{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b813a8",
   "metadata": {},
   "source": [
    "# PyTorch Computer Vision\n",
    "\n",
    "This notebook closely follows the material available at learnpytorch.io [[1]](https://www.learnpytorch.io/) with occasional refactoring and extension for consistency of style and to make connections with other parts of the package. It is also more extensive on examples and does less revisit of lower level concepts once discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ef5e5",
   "metadata": {},
   "source": [
    "### Computer Vision\n",
    "\n",
    "Computer vision [[2]](https://en.wikipedia.org/wiki/Computer_vision) is concerned with the extraction of information from images. It encompasses multiple sub-domains, we give a few examples below.\n",
    "\n",
    "* Object detection. Deals with detection of instances of objects of a certain class, like humans, buildings, or cars.\n",
    "* Motion estimation. The process of determining motion vectors that describe the transformation from one 2D image to another.\n",
    "* Image segmentation. Concerned with partitioning of an image into multiple regions based on some homogeneity criteria.\n",
    "\n",
    "In essence, anything that can be described in a visual sense can be a potential computer vision problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f679c3",
   "metadata": {},
   "source": [
    "### Sample data - Fashion-MNIST\n",
    "\n",
    "The MNIST database [[3]](https://en.wikipedia.org/wiki/MNIST_database) consists of handwritten digits used in training various image processing systems and consequently finds its usages in machine learning. Fashion-MNIST [[4]](https://github.com/zalandoresearch/fashion-mnist) is a fresh take on this database and comes with identical structure except for the fact that instead of digits in contains clothing images falling into 10 different classes. The Fashion-MNIST dataset will serve as our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None,\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7342ec1",
   "metadata": {},
   "source": [
    "The resulting datasets are `FashionMNIST` objects and contain, in a sequential format, tensor, by courtesy of the chosen `ToTensor` transformation, and label pairs, the latter referring to the position in the `classes` attribute of the dataset. Let us break up the data exploration into visible and easy-to-digest chunks; we start with the list of clothing types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a27496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931385a",
   "metadata": {},
   "source": [
    "The shape of image tensors is 1x28x28 which translates to the color channel, the height, and the width, respectively. Both size dimensions are pixels, the single dimensional color channel means that the image is greyscale.\n",
    "\n",
    "**Note.** This order is known as CHW. This abbreviation is commonly extended with an N prefix to form NCHW with N standing for the number of images. PyTorch generally accepts NCHW, but performs better on NHWC, a channel last format. Here, it will not make measureable difference. See [[5]](https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice) for more details and we refer to [[6]](https://en.wikipedia.org/wiki/Color_model) as well for various color models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c61fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.classes[label])\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099a31c",
   "metadata": {},
   "source": [
    "We may also visualize the data for several randomly picked image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ababd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "figure = plt.figure(figsize=(12, 8))\n",
    "nrows, ncols = 4, 4\n",
    "for i in range(1, nrows * ncols + 1):\n",
    "    index = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    image, label = train_data[index]\n",
    "    figure.add_subplot(nrows, ncols, i)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.title(train_data.classes[label])\n",
    "    plt.axis(False);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499f68f",
   "metadata": {},
   "source": [
    "### Detour - batch processing\n",
    "\n",
    "PyTorch is equipped with a powerful utility called `DataLoader` that turns datasets into a Python iterable. In an ideal world, the forward and backward passes across the model can be done all at once. In practice, we are limited by computational efficiency, and it is more performant to work in batches of the data. An important side effect is that gradient descent is also performed more often per epoch; once for each batch. Batch size is yet another hyperparameter of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "print(isinstance(train_dataloader, Iterable))\n",
    "print(isinstance(test_dataloader, Iterable))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952af5fe",
   "metadata": {},
   "source": [
    "### Linear model with flattening\n",
    "\n",
    "Recall that the problem of identifying clothing types correctly is essentially a multiclass classification problem. Our initial approach will be using linear layers with hidden neurons. However, our data for a single image is a proper third order tensor, and linear modeling requires a first order tensor, or simply, a vector format. PyTorch offers the `Flatten` layer for preparing data to be fed into a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTLinear(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        hidden_units,\n",
    "        output_shape,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=input_shape,\n",
    "                out_features=hidden_units\n",
    "            ),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units,\n",
    "                out_features=output_shape\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FashionMNISTLinear(\n",
    "    28*28,\n",
    "    10,\n",
    "    10,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90a357",
   "metadata": {},
   "source": [
    "As mentioned in the other notebook, the optimizer is problem-agnostic. For the loss function, we pick the generic version of cross entropy [[7]](https://en.wikipedia.org/wiki/Cross_entropy). We will also use a multiclass problem specific accuracy function from `torchmetrics` [[8]](https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#multiclassaccuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "accuracy_function = Accuracy(task=\"multiclass\", num_classes=10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epoch_count = 3\n",
    "\n",
    "for epoch in range(epoch_count):\n",
    "    print(f\"Epoch: {epoch}\\n--------\")\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (train_input, train_output) in enumerate(train_dataloader):\n",
    "        train_input, train_output = train_input.to(DEVICE), train_output.to(DEVICE)\n",
    "        \n",
    "        model.train()\n",
    "        train_classification = model(train_input)\n",
    "        \n",
    "        loss = loss_function(train_classification, train_output)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(train_input)}/{len(train_dataloader.dataset)} samples\")\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    test_loss, test_accuracy = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for test_input, test_output in test_dataloader:\n",
    "            test_input, test_output = test_input.to(DEVICE), test_output.to(DEVICE)\n",
    "            \n",
    "            test_classification = model(test_input)\n",
    "            \n",
    "            test_loss += loss_function(test_classification, test_output)\n",
    "            \n",
    "            test_accuracy += accuracy_function(test_output, test_classification.argmax(dim=1))\n",
    "        \n",
    "        test_loss /= len(test_dataloader)\n",
    "        \n",
    "        test_accuracy /= len(test_dataloader)\n",
    "    \n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2649e11",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Learn PyTorch for Deep Learning: Zero to Mastery book, accessed online on 2023.05.01 at https://www.learnpytorch.io/\n",
    "\n",
    "[2] Computer vision, Wikipedia article, accesssed online on 2023.05.01 at https://en.wikipedia.org/wiki/Computer_vision\n",
    "\n",
    "[3] MNIST database, Wikipedia article, accessed online on 2023.05.01 at https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "[4] Zalando Research, Fashion MNIST database, accessed online on 2023.05.01 at https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "[5] Efficient PyTorch: Tensor Memory Format Matters, blog entry, accessed online on 2023.05.01 at https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice\n",
    "\n",
    "[6] Color model, Wikipedia article, accessed online on 2023.05.01 at https://en.wikipedia.org/wiki/Color_model\n",
    "\n",
    "[7] Cross entropy, Wikipedia article, accessed online on 2023.05.01 at https://en.wikipedia.org/wiki/Cross_entropy\n",
    "\n",
    "[8] TorchMetrics, API documentation, accessed online on 2023.05.01 at https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#multiclassaccuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
