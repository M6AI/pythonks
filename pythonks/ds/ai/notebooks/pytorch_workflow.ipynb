{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484fb48f",
   "metadata": {},
   "source": [
    "# PyTorch Workflow\n",
    "\n",
    "This notebook closely follows the material available at learnpytorch.io [[1]](https://www.learnpytorch.io/) with occasional refactoring and extension for consistency of style and to make connections with other parts of the package. It is also more extensive on examples and does less revisit of lower level concepts once discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480912ab",
   "metadata": {},
   "source": [
    "### A Generic Workflow\n",
    "\n",
    "At the core of most machine learning models, the below steps are followed.\n",
    "\n",
    "- Take relevant historical data and map it to tensors.\n",
    "- Build or select a model/algorithm that is suitable for the problem to be solved.\n",
    "    - Decide on an loss function and an optimizer.\n",
    "    - Build a training loop.\n",
    "- Fit the model to the data and make a prediction.\n",
    "- Evaluate the model and improve iteratively.\n",
    "- Preserve the state of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf634e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # for inline visualization\n",
    "import torch\n",
    "from torch import nn  # contains the building blocks for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f1a65",
   "metadata": {},
   "source": [
    "### Example: Linear Regression\n",
    "\n",
    "To demonstrate the above workflow, we will generate a predictor $X$ and a target variable $Y$ with known linear (affine to be more precise) relationship\n",
    "\n",
    "$$\n",
    "Y = a X + b\n",
    "$$\n",
    "\n",
    "then use a portion of this data to train our model to estimate these parameters and consequently use it for prediction of the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156648ad",
   "metadata": {},
   "source": [
    "**Note.** In machine learning data can be just about anything. One of the immediate challenges to overcome is to find a proper representation of the input in terms of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_weight, true_bias = 0.7, 0.3\n",
    "predictor = torch.arange(0, 1, 0.02)\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e45515",
   "metadata": {},
   "source": [
    "Since the relationship is fixed, we readily generate the target variable from the predictor and the true weight and bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = true_weight * predictor + true_bias\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec64ee",
   "metadata": {},
   "source": [
    "When it comes to partition of the data, the following three-way split shall be considered: training set, validation set, and testing set. Each has its own purpose and rule of thumbs for size.\n",
    "\n",
    "- Training set is used by the model as  means of learning. It can attribute to 60-80% of the total data.\n",
    "- Validation set is used to fine tune the model. It is not always used and can make up 10-20% of the total data.\n",
    "- Testing set is the batch on which the model is evaluated. It consists of the rest of the data.\n",
    "\n",
    "Here, we ignore validation and use a generic Pareto split of 80% and 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c96ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = int(0.8 * predictor.size(dim=0))\n",
    "train_predictor, train_target = predictor[:train_cutoff], target[:train_cutoff]\n",
    "test_predictor, test_target = predictor[train_cutoff:], target[train_cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9aeb0b",
   "metadata": {},
   "source": [
    "We can visualize our data using a scatter plot, a fairly standard pick in the context of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(train_predictor, train_target, s=2, c=\"red\", label=\"Training data\")\n",
    "plt.scatter(test_predictor, test_target, s=2, c=\"blue\", label=\"Testing data\")\n",
    "plt.legend(prop={\"size\": 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6d379",
   "metadata": {},
   "source": [
    "In order to build a machine learning model, we will rely on the `Module` template provided by `torch.nn`.\n",
    "Due to inheritance we do not really need to care about low-level implementation.\n",
    "The main actors are the weight and bias parameters that will be represented as scalar tensors.\n",
    "However, it is important that we would like to use the associated gradients with respect to the yet to be defined loss function; thus, we require gradients during instantiation.\n",
    "The type used for these objects is the `Parameter` class which, when used in conjuction with, gets added to the parameters of the `Module`.\n",
    "Other than that `Parameter`s can be thought of as any other tensor.\n",
    "\n",
    "The bare minimum to produce a solution to the machine learning problem is to be able to predict using the model.\n",
    "The `forward` function defines how the prediction should be made with the parameters of the model.\n",
    "In this case, it is the linear regression formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._weight = nn.Parameter(\n",
    "            torch.randn(1, dtype=torch.float),  # randomized initial state\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        self._bias = nn.Parameter(\n",
    "            torch.randn(1, dtype=torch.float),  # randomized initial state\n",
    "            requires_grad=True,\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self._weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self._bias\n",
    "    \n",
    "    def forward(self, predictor):\n",
    "        return self.weight * predictor + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390bc65",
   "metadata": {},
   "source": [
    "Parameters and the state of the model can readily be accessed with inherited methods from `Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c810b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model = LinearRegressionModel()\n",
    "for parameter in sample_model.parameters():\n",
    "    print(parameter)\n",
    "print()\n",
    "print(sample_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971aa3d3",
   "metadata": {},
   "source": [
    "Assume we would like to make a prediction using the initial parameters. PyTorch is equipped with a context manager called `inference_mode` that ensures the code run within its context does not use the gradients and stops view tracking to improve performance of execution. In this particular example, it has no real benefits, however, it does once the number of parameters and evaluation steps blow up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    result = sample_model(test_predictor)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4756bde",
   "metadata": {},
   "source": [
    "Visualizing once again, the initial pick of parameters simply resulted in a random guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(train_predictor, train_target, s=2, c=\"red\", label=\"Training data\")\n",
    "plt.scatter(test_predictor, test_target, s=2, c=\"blue\", label=\"Testing data\")\n",
    "plt.scatter(test_predictor, result, s=2, c=\"green\", label=\"Model-predicted data\")\n",
    "plt.legend(prop={\"size\": 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a800c65",
   "metadata": {},
   "source": [
    "The model parameters can be improved iteratively by expressing the goodness of the prediction in terms of some loss function.\n",
    "Then we would pick an appropriate optimizer mechanism that determines how the parameters should be updated in order to decrease the loss.\n",
    "An example of a loss function would be mean absolute error while an example of an optimizer would be stochastic gradient descent.\n",
    "For a brief overview of each, see the Wikipedia articles [[2]](https://en.wikipedia.org/wiki/Mean_absolute_error) and [[3]](https://en.wikipedia.org/wiki/Gradient_descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.L1Loss()  # Mean absolute error\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=sample_model.parameters(),\n",
    "    lr=0.01\n",
    ")  # Stochastic gradient descent. `lr` is a so-called hyperparameter and subject to change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc2518",
   "metadata": {},
   "source": [
    "The training loop in which we leverage the loss function and the optimization step is structured as follows:\n",
    "- Forward pass performs forward calculations of the model across the training data.\n",
    "- Loss calculation evaluates the predictions against the true target.\n",
    "- Backpropagation computes the gradient of the loss function with respect for every model parameter to be updated, accumulating them using the chain rule. Note that each step requires gradients to be set to zero so that training steps do not interfere with each other beyond the parameters.\n",
    "- Update the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a087e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epoch_count = 100\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epoch_count):\n",
    "    sample_model.train()  # sets the model in training state\n",
    "    prediction = sample_model(train_predictor)\n",
    "    loss = loss_function(prediction, train_target)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    sample_model.eval()  # sets the model in evaluation state\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        test_prediction = sample_model(test_predictor)\n",
    "        test_loss = loss_function(test_prediction, test_target)\n",
    "    \n",
    "    train_losses.append(loss.detach().numpy())\n",
    "    test_losses.append(test_loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(list(range(1, epoch_count+1)), train_losses, label=\"Training MAE loss\")\n",
    "plt.plot(list(range(1, epoch_count+1)), test_losses, label=\"Testing MAE loss\")\n",
    "plt.legend({\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16dcbaf",
   "metadata": {},
   "source": [
    "Notice that we got \"fairly\" close to the actual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f832942",
   "metadata": {},
   "source": [
    "Let assume that we are satisfied with the model's performance. Now we can make predictions, but need to remember that we should set the model state into evaluation and use the inference mode for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictor = torch.arange(1.02, 1.20, 0.02)\n",
    "sample_model.eval()\n",
    "with torch.inference_mode():\n",
    "    new_prediction = sample_model(new_predictor)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc73fa",
   "metadata": {},
   "source": [
    "Finally, we may preserve and reuse the model. The standard approach is to pickle and write the model's state dictionary into a file, then load it when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(\n",
    "    obj=sample_model.state_dict(),\n",
    "    f=model_path / \"linear_regressor.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8804018",
   "metadata": {},
   "source": [
    "We can demonstrate the correct storage by reloading the state into a new instance of the model and repeat the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82949db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = LinearRegressionModel()\n",
    "trained_model.load_state_dict(torch.load(f=model_path / \"linear_regressor.pth\"))\n",
    "trained_model.eval()\n",
    "with torch.inference_mode():\n",
    "    new_prediction = trained_model(new_predictor)\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb076f0",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Learn PyTorch for Deep Learning: Zero to Mastery book, accessed online on 2023.04.02 at https://www.learnpytorch.io/\n",
    "\n",
    "[2] Mean absolute error, Wikipedia article, accessed online on 2023.04.02 at https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "\n",
    "[3] Gradient descent, Wikipedia article, accessed online on 2023.04.02 at https://en.wikipedia.org/wiki/Gradient_descent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
